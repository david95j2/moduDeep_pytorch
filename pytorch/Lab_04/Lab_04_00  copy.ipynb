{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train :  torch.Size([6, 2])\n",
      "y_train :  torch.Size([6, 1])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(2222)\n",
    "x_data = [[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]]\n",
    "y_data = [[0], [0], [0], [1], [1], [1]]\n",
    "x_train = torch.FloatTensor(x_data)\n",
    "y_train = torch.FloatTensor(y_data)\n",
    "\n",
    "print(\"x_train : \", x_train.shape)\n",
    "print(\"y_train : \", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6761],\n",
       "        [0.6286],\n",
       "        [0.3816],\n",
       "        [0.3951],\n",
       "        [0.2886],\n",
       "        [0.1618]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "   nn.Linear(2, 1),\n",
    "   nn.Sigmoid() \n",
    ")\n",
    "model(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "hypothesis : tensor([[0.6761],\n",
      "        [0.6286],\n",
      "        [0.3816],\n",
      "        [0.3951],\n",
      "        [0.2886],\n",
      "        [0.1618]], grad_fn=<SigmoidBackward0>)\n",
      "Epoch    0/100 Cost: 1.098616 Accuracy 16.67%\n",
      "\n",
      "hypothesis : tensor([[0.9429],\n",
      "        [0.9859],\n",
      "        [0.9800],\n",
      "        [0.9974],\n",
      "        [0.9989],\n",
      "        [0.9991]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.3569],\n",
      "        [0.2528],\n",
      "        [0.3833],\n",
      "        [0.2078],\n",
      "        [0.1877],\n",
      "        [0.2271]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.9419],\n",
      "        [0.9908],\n",
      "        [0.9957],\n",
      "        [0.9996],\n",
      "        [0.9999],\n",
      "        [1.0000]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.3459],\n",
      "        [0.3322],\n",
      "        [0.7342],\n",
      "        [0.5898],\n",
      "        [0.7097],\n",
      "        [0.8825]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.3391],\n",
      "        [0.3440],\n",
      "        [0.7677],\n",
      "        [0.6481],\n",
      "        [0.7754],\n",
      "        [0.9223]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.2586],\n",
      "        [0.2340],\n",
      "        [0.6894],\n",
      "        [0.4899],\n",
      "        [0.6300],\n",
      "        [0.8594]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.3967],\n",
      "        [0.4851],\n",
      "        [0.8709],\n",
      "        [0.8497],\n",
      "        [0.9326],\n",
      "        [0.9830]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.1221],\n",
      "        [0.0752],\n",
      "        [0.4453],\n",
      "        [0.1549],\n",
      "        [0.2157],\n",
      "        [0.5141]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.7950],\n",
      "        [0.9560],\n",
      "        [0.9943],\n",
      "        [0.9988],\n",
      "        [0.9998],\n",
      "        [1.0000]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.1341],\n",
      "        [0.1195],\n",
      "        [0.7205],\n",
      "        [0.4475],\n",
      "        [0.6643],\n",
      "        [0.9310]], grad_fn=<SigmoidBackward0>)\n",
      "Epoch   10/100 Cost: 0.471762 Accuracy 66.67%\n",
      "\n",
      "hypothesis : tensor([[0.2519],\n",
      "        [0.3355],\n",
      "        [0.8880],\n",
      "        [0.8446],\n",
      "        [0.9469],\n",
      "        [0.9922]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.0890],\n",
      "        [0.0656],\n",
      "        [0.5600],\n",
      "        [0.2378],\n",
      "        [0.3968],\n",
      "        [0.8026]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.4730],\n",
      "        [0.7400],\n",
      "        [0.9747],\n",
      "        [0.9869],\n",
      "        [0.9974],\n",
      "        [0.9997]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.0669],\n",
      "        [0.0490],\n",
      "        [0.5500],\n",
      "        [0.2151],\n",
      "        [0.3873],\n",
      "        [0.8238]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.4161],\n",
      "        [0.7023],\n",
      "        [0.9757],\n",
      "        [0.9872],\n",
      "        [0.9977],\n",
      "        [0.9998]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.0598],\n",
      "        [0.0481],\n",
      "        [0.5892],\n",
      "        [0.2575],\n",
      "        [0.4759],\n",
      "        [0.8867]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.2974],\n",
      "        [0.5412],\n",
      "        [0.9599],\n",
      "        [0.9718],\n",
      "        [0.9947],\n",
      "        [0.9995]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.0539],\n",
      "        [0.0457],\n",
      "        [0.5772],\n",
      "        [0.2616],\n",
      "        [0.4908],\n",
      "        [0.8946]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.2690],\n",
      "        [0.5144],\n",
      "        [0.9558],\n",
      "        [0.9700],\n",
      "        [0.9944],\n",
      "        [0.9995]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.0507],\n",
      "        [0.0461],\n",
      "        [0.5731],\n",
      "        [0.2795],\n",
      "        [0.5234],\n",
      "        [0.9069]], grad_fn=<SigmoidBackward0>)\n",
      "Epoch   20/100 Cost: 0.495068 Accuracy 66.67%\n",
      "\n",
      "hypothesis : tensor([[0.2356],\n",
      "        [0.4693],\n",
      "        [0.9465],\n",
      "        [0.9637],\n",
      "        [0.9932],\n",
      "        [0.9993]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.0483],\n",
      "        [0.0467],\n",
      "        [0.5598],\n",
      "        [0.2912],\n",
      "        [0.5432],\n",
      "        [0.9115]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.2167],\n",
      "        [0.4500],\n",
      "        [0.9390],\n",
      "        [0.9609],\n",
      "        [0.9926],\n",
      "        [0.9993]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.0462],\n",
      "        [0.0476],\n",
      "        [0.5439],\n",
      "        [0.3015],\n",
      "        [0.5593],\n",
      "        [0.9140]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.2027],\n",
      "        [0.4387],\n",
      "        [0.9317],\n",
      "        [0.9592],\n",
      "        [0.9923],\n",
      "        [0.9992]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.0444],\n",
      "        [0.0485],\n",
      "        [0.5266],\n",
      "        [0.3109],\n",
      "        [0.5731],\n",
      "        [0.9154]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.1913],\n",
      "        [0.4315],\n",
      "        [0.9242],\n",
      "        [0.9581],\n",
      "        [0.9921],\n",
      "        [0.9992]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.0427],\n",
      "        [0.0495],\n",
      "        [0.5090],\n",
      "        [0.3199],\n",
      "        [0.5858],\n",
      "        [0.9163]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.1813],\n",
      "        [0.4263],\n",
      "        [0.9165],\n",
      "        [0.9574],\n",
      "        [0.9920],\n",
      "        [0.9991]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.0411],\n",
      "        [0.0505],\n",
      "        [0.4915],\n",
      "        [0.3288],\n",
      "        [0.5979],\n",
      "        [0.9170]], grad_fn=<SigmoidBackward0>)\n",
      "Epoch   30/100 Cost: 0.413882 Accuracy 83.33%\n",
      "\n",
      "hypothesis : tensor([[0.1721],\n",
      "        [0.4217],\n",
      "        [0.9083],\n",
      "        [0.9568],\n",
      "        [0.9919],\n",
      "        [0.9991]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.0397],\n",
      "        [0.0516],\n",
      "        [0.4744],\n",
      "        [0.3378],\n",
      "        [0.6098],\n",
      "        [0.9176]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.1635],\n",
      "        [0.4172],\n",
      "        [0.8995],\n",
      "        [0.9561],\n",
      "        [0.9917],\n",
      "        [0.9990]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.0383],\n",
      "        [0.0527],\n",
      "        [0.4578],\n",
      "        [0.3469],\n",
      "        [0.6215],\n",
      "        [0.9184]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.1553],\n",
      "        [0.4125],\n",
      "        [0.8901],\n",
      "        [0.9553],\n",
      "        [0.9916],\n",
      "        [0.9989]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.0371],\n",
      "        [0.0538],\n",
      "        [0.4418],\n",
      "        [0.3562],\n",
      "        [0.6331],\n",
      "        [0.9192]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.1475],\n",
      "        [0.4075],\n",
      "        [0.8799],\n",
      "        [0.9545],\n",
      "        [0.9914],\n",
      "        [0.9989]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.0359],\n",
      "        [0.0550],\n",
      "        [0.4265],\n",
      "        [0.3657],\n",
      "        [0.6447],\n",
      "        [0.9201]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.1400],\n",
      "        [0.4021],\n",
      "        [0.8688],\n",
      "        [0.9534],\n",
      "        [0.9912],\n",
      "        [0.9988]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.0348],\n",
      "        [0.0562],\n",
      "        [0.4119],\n",
      "        [0.3755],\n",
      "        [0.6563],\n",
      "        [0.9211]], grad_fn=<SigmoidBackward0>)\n",
      "Epoch   40/100 Cost: 0.351191 Accuracy 83.33%\n",
      "\n",
      "hypothesis : tensor([[0.1329],\n",
      "        [0.3963],\n",
      "        [0.8570],\n",
      "        [0.9523],\n",
      "        [0.9910],\n",
      "        [0.9987]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.0338],\n",
      "        [0.0575],\n",
      "        [0.3980],\n",
      "        [0.3855],\n",
      "        [0.6679],\n",
      "        [0.9222]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.1260],\n",
      "        [0.3900],\n",
      "        [0.8441],\n",
      "        [0.9509],\n",
      "        [0.9907],\n",
      "        [0.9986]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.0329],\n",
      "        [0.0589],\n",
      "        [0.3849],\n",
      "        [0.3959],\n",
      "        [0.6795],\n",
      "        [0.9234]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.1194],\n",
      "        [0.3832],\n",
      "        [0.8303],\n",
      "        [0.9493],\n",
      "        [0.9904],\n",
      "        [0.9985]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.0321],\n",
      "        [0.0604],\n",
      "        [0.3725],\n",
      "        [0.4067],\n",
      "        [0.6912],\n",
      "        [0.9248]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.1131],\n",
      "        [0.3759],\n",
      "        [0.8155],\n",
      "        [0.9475],\n",
      "        [0.9900],\n",
      "        [0.9984]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.0313],\n",
      "        [0.0620],\n",
      "        [0.3609],\n",
      "        [0.4180],\n",
      "        [0.7030],\n",
      "        [0.9263]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.1070],\n",
      "        [0.3682],\n",
      "        [0.7995],\n",
      "        [0.9454],\n",
      "        [0.9895],\n",
      "        [0.9983]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.0306],\n",
      "        [0.0637],\n",
      "        [0.3502],\n",
      "        [0.4296],\n",
      "        [0.7148],\n",
      "        [0.9279]], grad_fn=<SigmoidBackward0>)\n",
      "Epoch   50/100 Cost: 0.297210 Accuracy 83.33%\n",
      "\n",
      "hypothesis : tensor([[0.1011],\n",
      "        [0.3598],\n",
      "        [0.7823],\n",
      "        [0.9430],\n",
      "        [0.9890],\n",
      "        [0.9981]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.0300],\n",
      "        [0.0655],\n",
      "        [0.3402],\n",
      "        [0.4419],\n",
      "        [0.7268],\n",
      "        [0.9297]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.0956],\n",
      "        [0.3510],\n",
      "        [0.7640],\n",
      "        [0.9402],\n",
      "        [0.9883],\n",
      "        [0.9979]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.0294],\n",
      "        [0.0675],\n",
      "        [0.3311],\n",
      "        [0.4546],\n",
      "        [0.7388],\n",
      "        [0.9316]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.0902],\n",
      "        [0.3417],\n",
      "        [0.7443],\n",
      "        [0.9371],\n",
      "        [0.9876],\n",
      "        [0.9977]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.0289],\n",
      "        [0.0697],\n",
      "        [0.3228],\n",
      "        [0.4681],\n",
      "        [0.7510],\n",
      "        [0.9337]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.0851],\n",
      "        [0.3318],\n",
      "        [0.7234],\n",
      "        [0.9335],\n",
      "        [0.9868],\n",
      "        [0.9975]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.0285],\n",
      "        [0.0720],\n",
      "        [0.3154],\n",
      "        [0.4822],\n",
      "        [0.7633],\n",
      "        [0.9360]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.0801],\n",
      "        [0.3215],\n",
      "        [0.7012],\n",
      "        [0.9294],\n",
      "        [0.9858],\n",
      "        [0.9972]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.0282],\n",
      "        [0.0746],\n",
      "        [0.3089],\n",
      "        [0.4970],\n",
      "        [0.7757],\n",
      "        [0.9384]], grad_fn=<SigmoidBackward0>)\n",
      "Epoch   60/100 Cost: 0.248717 Accuracy 83.33%\n",
      "\n",
      "hypothesis : tensor([[0.0754],\n",
      "        [0.3106],\n",
      "        [0.6777],\n",
      "        [0.9247],\n",
      "        [0.9846],\n",
      "        [0.9969]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.0279],\n",
      "        [0.0774],\n",
      "        [0.3032],\n",
      "        [0.5126],\n",
      "        [0.7882],\n",
      "        [0.9410]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.0709],\n",
      "        [0.2994],\n",
      "        [0.6530],\n",
      "        [0.9194],\n",
      "        [0.9833],\n",
      "        [0.9965]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.0277],\n",
      "        [0.0805],\n",
      "        [0.2984],\n",
      "        [0.5289],\n",
      "        [0.8008],\n",
      "        [0.9437]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.0666],\n",
      "        [0.2877],\n",
      "        [0.6272],\n",
      "        [0.9134],\n",
      "        [0.9818],\n",
      "        [0.9960]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.0276],\n",
      "        [0.0840],\n",
      "        [0.2946],\n",
      "        [0.5461],\n",
      "        [0.8134],\n",
      "        [0.9466]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.0625],\n",
      "        [0.2758],\n",
      "        [0.6005],\n",
      "        [0.9066],\n",
      "        [0.9800],\n",
      "        [0.9954]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.0275],\n",
      "        [0.0877],\n",
      "        [0.2917],\n",
      "        [0.5641],\n",
      "        [0.8260],\n",
      "        [0.9495]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.0587],\n",
      "        [0.2638],\n",
      "        [0.5731],\n",
      "        [0.8990],\n",
      "        [0.9780],\n",
      "        [0.9948]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.0275],\n",
      "        [0.0918],\n",
      "        [0.2896],\n",
      "        [0.5827],\n",
      "        [0.8385],\n",
      "        [0.9526]], grad_fn=<SigmoidBackward0>)\n",
      "Epoch   70/100 Cost: 0.205165 Accuracy 100.00%\n",
      "\n",
      "hypothesis : tensor([[0.0550],\n",
      "        [0.2516],\n",
      "        [0.5453],\n",
      "        [0.8906],\n",
      "        [0.9756],\n",
      "        [0.9941]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.0276],\n",
      "        [0.0962],\n",
      "        [0.2885],\n",
      "        [0.6019],\n",
      "        [0.8507],\n",
      "        [0.9557]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.0515],\n",
      "        [0.2396],\n",
      "        [0.5174],\n",
      "        [0.8813],\n",
      "        [0.9730],\n",
      "        [0.9932]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.0277],\n",
      "        [0.1010],\n",
      "        [0.2882],\n",
      "        [0.6215],\n",
      "        [0.8626],\n",
      "        [0.9589]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.0483],\n",
      "        [0.2279],\n",
      "        [0.4899],\n",
      "        [0.8714],\n",
      "        [0.9701],\n",
      "        [0.9923]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.0279],\n",
      "        [0.1061],\n",
      "        [0.2886],\n",
      "        [0.6414],\n",
      "        [0.8741],\n",
      "        [0.9619]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.0453],\n",
      "        [0.2167],\n",
      "        [0.4632],\n",
      "        [0.8609],\n",
      "        [0.9670],\n",
      "        [0.9912]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.0281],\n",
      "        [0.1115],\n",
      "        [0.2897],\n",
      "        [0.6610],\n",
      "        [0.8849],\n",
      "        [0.9649]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.0426],\n",
      "        [0.2061],\n",
      "        [0.4377],\n",
      "        [0.8500],\n",
      "        [0.9636],\n",
      "        [0.9900]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.0283],\n",
      "        [0.1171],\n",
      "        [0.2913],\n",
      "        [0.6802],\n",
      "        [0.8949],\n",
      "        [0.9678]], grad_fn=<SigmoidBackward0>)\n",
      "Epoch   80/100 Cost: 0.171123 Accuracy 100.00%\n",
      "\n",
      "hypothesis : tensor([[0.0401],\n",
      "        [0.1963],\n",
      "        [0.4138],\n",
      "        [0.8392],\n",
      "        [0.9602],\n",
      "        [0.9888]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.0285],\n",
      "        [0.1227],\n",
      "        [0.2932],\n",
      "        [0.6985],\n",
      "        [0.9041],\n",
      "        [0.9704]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.0378],\n",
      "        [0.1874],\n",
      "        [0.3919],\n",
      "        [0.8288],\n",
      "        [0.9568],\n",
      "        [0.9876]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.0286],\n",
      "        [0.1282],\n",
      "        [0.2950],\n",
      "        [0.7155],\n",
      "        [0.9123],\n",
      "        [0.9727]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.0358],\n",
      "        [0.1797],\n",
      "        [0.3723],\n",
      "        [0.8192],\n",
      "        [0.9537],\n",
      "        [0.9864]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.0287],\n",
      "        [0.1333],\n",
      "        [0.2966],\n",
      "        [0.7308],\n",
      "        [0.9194],\n",
      "        [0.9748]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.0340],\n",
      "        [0.1730],\n",
      "        [0.3550],\n",
      "        [0.8107],\n",
      "        [0.9509],\n",
      "        [0.9853]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.0287],\n",
      "        [0.1379],\n",
      "        [0.2976],\n",
      "        [0.7443],\n",
      "        [0.9255],\n",
      "        [0.9766]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.0325],\n",
      "        [0.1674],\n",
      "        [0.3401],\n",
      "        [0.8038],\n",
      "        [0.9487],\n",
      "        [0.9843]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.0286],\n",
      "        [0.1417],\n",
      "        [0.2979],\n",
      "        [0.7557],\n",
      "        [0.9305],\n",
      "        [0.9781]], grad_fn=<SigmoidBackward0>)\n",
      "Epoch   90/100 Cost: 0.151622 Accuracy 100.00%\n",
      "\n",
      "hypothesis : tensor([[0.0311],\n",
      "        [0.1629],\n",
      "        [0.3274],\n",
      "        [0.7985],\n",
      "        [0.9470],\n",
      "        [0.9836]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.0283],\n",
      "        [0.1448],\n",
      "        [0.2973],\n",
      "        [0.7651],\n",
      "        [0.9346],\n",
      "        [0.9793]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.0299],\n",
      "        [0.1593],\n",
      "        [0.3167],\n",
      "        [0.7948],\n",
      "        [0.9460],\n",
      "        [0.9831]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.0279],\n",
      "        [0.1469],\n",
      "        [0.2958],\n",
      "        [0.7727],\n",
      "        [0.9379],\n",
      "        [0.9803]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.0288],\n",
      "        [0.1564],\n",
      "        [0.3078],\n",
      "        [0.7925],\n",
      "        [0.9455],\n",
      "        [0.9828]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.0275],\n",
      "        [0.1483],\n",
      "        [0.2935],\n",
      "        [0.7787],\n",
      "        [0.9405],\n",
      "        [0.9810]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.0279],\n",
      "        [0.1542],\n",
      "        [0.3002],\n",
      "        [0.7915],\n",
      "        [0.9454],\n",
      "        [0.9827]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.0269],\n",
      "        [0.1491],\n",
      "        [0.2906],\n",
      "        [0.7834],\n",
      "        [0.9426],\n",
      "        [0.9817]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.0270],\n",
      "        [0.1525],\n",
      "        [0.2938],\n",
      "        [0.7915],\n",
      "        [0.9458],\n",
      "        [0.9827]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "hypothesis : tensor([[0.0263],\n",
      "        [0.1493],\n",
      "        [0.2873],\n",
      "        [0.7871],\n",
      "        [0.9443],\n",
      "        [0.9822]], grad_fn=<SigmoidBackward0>)\n",
      "Epoch  100/100 Cost: 0.140279 Accuracy 100.00%\n"
     ]
    }
   ],
   "source": [
    "# optimizer 설정\n",
    "optimizer = optim.SGD(model.parameters(), lr=1)\n",
    "\n",
    "nb_epochs = 100\n",
    "\n",
    "running_loss = []\n",
    "for epoch in range(nb_epochs + 1):\n",
    "\n",
    "    # H(x) 계산\n",
    "    hypothesis = model(x_train)\n",
    "    print(f\"\\nhypothesis : {hypothesis}\")\n",
    "\n",
    "    # cost 계산\n",
    "    cost = F.binary_cross_entropy(hypothesis, y_train)\n",
    "    running_loss.append(cost)\n",
    "    \n",
    "    # cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 20번마다 로그 출력\n",
    "    if epoch % 10 == 0:\n",
    "        prediction = hypothesis >= torch.FloatTensor([0.5]) # 예측값이 0.5를 넘으면 True로 간주\n",
    "        correct_prediction = prediction.float() == y_train # 실제값과 일치하는 경우만 True로 간주\n",
    "        accuracy = correct_prediction.sum().item() / len(correct_prediction) # 정확도를 계산\n",
    "        print('Epoch {:4d}/{} Cost: {:.6f} Accuracy {:2.2f}%'.format( # 각 에포크마다 정확도를 출력\n",
    "            epoch, nb_epochs, cost.item(), accuracy * 100,\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = plt.subplot()\n",
    "plt.plot(torch.tensor(running_loss).detach(), 'r')\n",
    "ax.set_title('Cost graph of logistic regression (demo)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Cost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0262],\n",
      "        [0.1511],\n",
      "        [0.2882],\n",
      "        [0.7922],\n",
      "        [0.9464],\n",
      "        [0.9828]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(model(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dbfa867c80980d085025f7ec622c1a9d9521b336ebdba89779c207447b7ffca6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
