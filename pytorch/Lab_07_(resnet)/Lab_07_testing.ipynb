{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms as transforms\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "torch.manual_seed(50)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = torchvision.datasets.ImageFolder(root=\"../Lab_05_(inception)/baby_data/train\", transform=transforms.ToTensor())\n",
    "val_ds = torchvision.datasets.ImageFolder(root=\"../Lab_05_(inception)/baby_data/val\", transform=transforms.ToTensor())\n",
    "test_ds = torchvision.datasets.ImageFolder(root=\"../Lab_05_(inception)/baby_data/test\", transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Mean(data):\n",
    "    RGB = [np.mean(x.numpy(), axis=(1, 2)) for x, _ in data]\n",
    "    mean_R = np.mean([m[0] for m in RGB])\n",
    "    mean_G = np.mean([m[1] for m in RGB])\n",
    "    mean_B = np.mean([m[2] for m in RGB])\n",
    "\n",
    "    return mean_R, mean_G, mean_B\n",
    "\n",
    "\n",
    "def get_Std(data):\n",
    "    RGB = [np.std(x.numpy(), axis=(1, 2)) for x, _ in data]\n",
    "    std_R = np.mean([s[0] for s in RGB])\n",
    "    std_G = np.mean([s[1] for s in RGB])\n",
    "    std_B = np.mean([s[2] for s in RGB])\n",
    "\n",
    "    return std_R, std_G, std_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RGB 평균 구하기\n",
    "train_meanR, train_meanG, train_meanB = get_Mean(train_ds)\n",
    "val_meanR, val_meanG, val_meanB = get_Mean(val_ds)\n",
    "test_meanR, test_meanG, test_meanB = get_Mean(test_ds)\n",
    "\n",
    "# RGB 표준편차 구하기\n",
    "train_stdR, train_stdG, train_stdB = get_Std(train_ds)\n",
    "val_stdR, val_stdG, val_stdB = get_Std(val_ds)\n",
    "test_stdR, test_stdG, test_stdB = get_Std(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train Mean : \", train_meanR, train_meanG, train_meanB)\n",
    "print(\"train Std : \", train_stdR, train_stdG, train_stdB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trans(width, height, m_r, m_g, m_b, s_r, s_g, s_b):\n",
    "    transformation = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((width, height)),\n",
    "        transforms.Normalize([m_r, m_g, m_b], [s_r, s_g, s_b]),\n",
    "    ])\n",
    "    return transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transformation = get_trans(224, 224, train_meanR, train_meanG, train_meanB,\n",
    "                                 train_stdR, train_stdG, train_stdB)\n",
    "\n",
    "val_transformation = get_trans(224, 224, val_meanR, val_meanG, val_meanB,\n",
    "                               val_stdR, val_stdG, val_stdB)\n",
    "\n",
    "test_transformation = get_trans(224, 224, test_meanR, test_meanG, test_meanB,\n",
    "                                test_stdR, test_stdG, test_stdB)\n",
    "\n",
    "train_ds.transform = train_transformation\n",
    "val_ds.transform = val_transformation\n",
    "test_ds.transform = test_transformation\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "val_dl = DataLoader(val_ds, batch_size=32, shuffle=True)\n",
    "test_dl = DataLoader(test_ds, batch_size=32, shuffle=True)\n",
    "\n",
    "classes = ('bgs', 'crying')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display sample images\n",
    "def show(img, y=None, color=True):\n",
    "    npimg = img.numpy()\n",
    "    npimg_tr = np.transpose(npimg, (1, 2, 0))\n",
    "    plt.imshow(npimg_tr)\n",
    "\n",
    "    if y is not None:\n",
    "        plt.title('labels: ' + str(y))\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "grid_size = 1\n",
    "rnd_inds = np.random.randint(0, len(train_ds), grid_size)\n",
    "\n",
    "x_grid = [train_ds[i][0] for i in rnd_inds]\n",
    "y_grid = [train_ds[i][1] for i in rnd_inds]\n",
    "\n",
    "x_grid = torchvision.utils.make_grid(x_grid, nrow=5, padding=0)\n",
    "\n",
    "# call helper function\n",
    "plt.figure(figsize=(10, 10))\n",
    "show(x_grid, y_grid)\n",
    "\n",
    "print(x_grid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self,input_ch,output_ch,stride=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.basick_layer = nn.Sequential(\n",
    "            nn.Conv2d(input_ch, output_ch, kernel_size=3, stride=stride, padding=1),\n",
    "            nn.BatchNorm2d(output_ch),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(output_ch, output_ch, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(output_ch),\n",
    "        )\n",
    "        \n",
    "        self.shortcut = nn.Sequential()\n",
    "        \n",
    "        if stride != 1:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(input_ch,output_ch,kernel_size=1,stride=2),\n",
    "                nn.BatchNorm2d(output_ch)\n",
    "            )\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.basick_layer(x) + self.shortcut(x)\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet34(nn.Module):\n",
    "    def __init__(self, block,num_classes=2, init_weight=True):\n",
    "        super().__init__()\n",
    "        self.in_channel = 64\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2_x = self.make_block(block, out_channel=64, num_block=3, stride=1)\n",
    "        self.conv3_x = self.make_block(block, out_channel=128, num_block=4, stride=2)\n",
    "        self.conv4_x = self.make_block(block, out_channel=256, num_block=6, stride=2)\n",
    "        self.conv5_x = self.make_block(block, out_channel=512, num_block=3, stride=2)\n",
    "        self.avgpool1 = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(512,num_classes)\n",
    "        \n",
    "        if init_weight:\n",
    "            self.weights_initialize()\n",
    "\n",
    "    def make_block(self,block, out_channel, num_block, stride):\n",
    "        stride_list = [stride] + [1] * (num_block - 1)\n",
    "        layer = []\n",
    "        for i in stride_list:\n",
    "            layer.append(block(self.in_channel,out_channel,i))\n",
    "            self.in_channel = out_channel\n",
    "        return nn.Sequential(*layer)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2_x(x)\n",
    "        x = self.conv3_x(x)\n",
    "        x = self.conv4_x(x)\n",
    "        x = self.conv5_x(x)\n",
    "        x = self.avgpool1(x)\n",
    "        x = x.view(x.shape[0],-1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    def weights_initialize(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(\n",
    "                    m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Resnet34(BasicBlock).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model, input_size=(3, 224, 224), device=device.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "loss_func = nn.CrossEntropyLoss(reduction='sum')\n",
    "opt = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "lr_scheduler = CosineAnnealingWarmRestarts(opt, T_0=10, T_mult=1, eta_min=0.00001, last_epoch=-1)\n",
    "\n",
    "\n",
    "def get_lr(opt):\n",
    "    for param_group in opt.param_groups:\n",
    "        return param_group['lr']\n",
    "\n",
    "\n",
    "def metric_batch(output, target):\n",
    "    pred = output.argmax(dim=1, keepdim=True)\n",
    "    corrects = pred.eq(target.view_as(pred)).sum().item()\n",
    "    return corrects\n",
    "\n",
    "\n",
    "def loss_batch(loss_func, output, target, opt=None):\n",
    "    loss = loss_func(output, target)\n",
    "    metric_b = metric_batch(output, target)\n",
    "\n",
    "    if opt is not None:\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    return loss.item(), metric_b\n",
    "\n",
    "\n",
    "def loss_epoch(model, loss_func, dataset_dl, opt=None):\n",
    "    running_loss = 0.0\n",
    "    running_metric = 0.0\n",
    "    len_data = len(dataset_dl.dataset)\n",
    "\n",
    "    for xb, yb in dataset_dl:\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "        output = model(xb)\n",
    "\n",
    "        loss_b, metric_b = loss_batch(loss_func, output, yb, opt)\n",
    "\n",
    "        running_loss += loss_b\n",
    "\n",
    "        if metric_b is not None:\n",
    "            running_metric += metric_b\n",
    "\n",
    "    loss = running_loss / len_data\n",
    "    metric = running_metric / len_data\n",
    "\n",
    "    return loss, metric\n",
    "\n",
    "\n",
    "def train_val(model, params):\n",
    "    num_epochs = params[\"num_epochs\"] \n",
    "    loss_func = params[\"loss_func\"] \n",
    "    opt = params[\"optimizer\"] \n",
    "    train_dl = params[\"train_dl\"]\n",
    "    val_dl = params[\"val_dl\"]\n",
    "    lr_scheduler = params[\"lr_scheduler\"]\n",
    "    path2weights = params[\"path2weights\"]\n",
    "\n",
    "    loss_history = {'train': [], 'val': []}\n",
    "    metric_history = {'train': [], 'val': []}\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    best_loss = float('inf')\n",
    "\n",
    "    start_time = time.time()\n",
    "    for epoch in range(num_epochs):\n",
    "        current_lr = get_lr(opt)\n",
    "        print('Epoch {}/{}, current lr={}'.format(epoch, num_epochs - 1, current_lr))\n",
    "\n",
    "        model.train()\n",
    "        train_loss, train_metric = loss_epoch(model, loss_func, train_dl, opt)\n",
    "        loss_history['train'].append(train_loss)\n",
    "        metric_history['train'].append(train_metric)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss, val_metric = loss_epoch(model, loss_func, val_dl)\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "            torch.save(model.state_dict(), path2weights)\n",
    "            print('Message : Copied best model')\n",
    "\n",
    "        loss_history['val'].append(val_loss)\n",
    "        metric_history['val'].append(val_metric)\n",
    "\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        print('train loss: %.6f, val loss: %.6f, val_accuracy: %.2f, time: %.4f min' % (train_loss, val_loss, 100*val_metric, (time.time()-start_time)/60))\n",
    "        print('-'*10)\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    return model, loss_history, metric_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definc the training parameters\n",
    "params_train = {\n",
    "    'num_epochs': 100,\n",
    "    'optimizer': opt,\n",
    "    'loss_func': loss_func,\n",
    "    'train_dl': train_dl,\n",
    "    'val_dl': val_dl,\n",
    "    'lr_scheduler': lr_scheduler,\n",
    "    'path2weights': './models/weights.pt',\n",
    "}\n",
    "\n",
    "# create the directory that stores weights.pt\n",
    "\n",
    "\n",
    "def createFolder(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSerror:\n",
    "        print('Error')\n",
    "\n",
    "\n",
    "createFolder('./models')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, loss_hist, metric_hist = train_val(model, params_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Validation Progress\n",
    "num_epochs = params_train[\"num_epochs\"]\n",
    "\n",
    "# plot loss progress\n",
    "plt.title(\"Train-Val Loss\")\n",
    "plt.plot(range(1, num_epochs+1), loss_hist[\"train\"], label=\"train\")\n",
    "plt.plot(range(1, num_epochs+1), loss_hist[\"val\"], label=\"val\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Training Epochs\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# plot accuracy progress\n",
    "plt.title(\"Train-Val Accuracy\")\n",
    "plt.plot(range(1, num_epochs+1), metric_hist[\"train\"], label=\"train\")\n",
    "plt.plot(range(1, num_epochs+1), metric_hist[\"val\"], label=\"val\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Training Epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_total = 0\n",
    "    test_correct = 0\n",
    "    for data in test_dl:\n",
    "        model.eval()\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        test_loss.append(loss)\n",
    "\n",
    "        _, predicted = torch.max(outputs[0].data, 1)\n",
    "\n",
    "        test_total += labels.size(0)\n",
    "\n",
    "        test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Test : Accuracy of the network on the {len(test_ds)} test images: {(100 * test_correct / test_total):.2f} loss : {loss:.2f}')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dfbd672e28bbed90d5d5d40f9aaa2ef1070e421b4c18d3a50b2720b9a48f0aa6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
